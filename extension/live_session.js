import { GoogleGenAI, Modality } from './lib/gemini-sdk.js';

// --- DOMè¦ç´  ---
const stopButton = document.getElementById('stopButton');
const statusDiv = document.getElementById('status');

// --- å®šæ•° ---
const GEMINI_API_KEY = 'AIzaSyBXYC5wZeheBszWRs6-kWn1jbqOqRLZyGY';
const MODEL_NAME = 'gemini-2.5-flash-preview-native-audio-dialog';
const INPUT_SAMPLE_RATE = 16000;
const OUTPUT_SAMPLE_RATE = 24000;

// --- ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•° ---
let genAI;
let session;
let inputAudioContext;
let outputAudioContext;
let mediaStream;
let audioWorkletNode;
let sourceNode;
let isRecording = false;

// éŸ³å£°å†ç”Ÿã‚­ãƒ¥ãƒ¼
const audioQueue = [];
let isPlaying = false;
const currentSourceRef = { current: null };

// --- ãƒ¡ã‚¤ãƒ³å‡¦ç† ---
async function main() {
  updateStatus('Geminiã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’åˆæœŸåŒ–ã—ã¦ã„ã¾ã™...');
  const initSuccess = await initialize();
  if (!initSuccess) {
    updateStatus('ã‚¨ãƒ©ãƒ¼: ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒ—ãƒ­ã‚»ãƒƒã‚µã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸã€‚');
    return;
  }

  updateStatus('Geminiã¨ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’é–‹å§‹ã—ã¾ã™...');
  const sessionSuccess = await startSession();

  if (sessionSuccess) {
    updateStatus('ãƒã‚¤ã‚¯ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ã‚’è¦æ±‚ã—ã¾ã™...');
    await startRecording();
  } else {
    updateStatus('ã‚¨ãƒ©ãƒ¼: Geminiã‚»ãƒƒã‚·ãƒ§ãƒ³ã®é–‹å§‹ã«å¤±æ•—ã—ã¾ã—ãŸã€‚');
  }
}

// --- åˆæœŸåŒ– ---
async function initialize() {
  try {
    genAI = new GoogleGenAI({
      apiKey: GEMINI_API_KEY
    });
    inputAudioContext = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: INPUT_SAMPLE_RATE });
    outputAudioContext = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: OUTPUT_SAMPLE_RATE });
    
    await inputAudioContext.audioWorklet.addModule('audio-processor.js');
    return true;
  } catch (e) {
    console.error('åˆæœŸåŒ–ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ:', e);
    return false;
  }
}

// --- Geminiã‚»ãƒƒã‚·ãƒ§ãƒ³ ---
async function startSession() {
  try {
    session = await genAI.live.connect({
      model: MODEL_NAME,
      config: {
        responseModalities: [Modality.AUDIO],
        speechConfig: { voiceConfig: { prebuiltVoiceConfig: { voiceName: 'Orus' } } },
      },
      tools: [{ googleSearch: {} }],
      callbacks: {
        onopen: () => updateStatus('Geminiã¨ã®æ¥ç¶šãŒç¢ºç«‹ã—ã¾ã—ãŸã€‚'),
        onmessage: handleGeminiMessage,
        onerror: (error) => updateStatus(`ã‚¨ãƒ©ãƒ¼: ${error.message}`),
        onclose: () => {
          updateStatus('Geminiã‚»ãƒƒã‚·ãƒ§ãƒ³ãŒçµ‚äº†ã—ã¾ã—ãŸã€‚');
          if (isRecording) stopRecording();
        },
      },
    });
    return true;
  } catch (e) {
    console.error('Geminiã‚»ãƒƒã‚·ãƒ§ãƒ³ã®é–‹å§‹ã«å¤±æ•—ã—ã¾ã—ãŸ:', e);
    return false;
  }
}

async function handleGeminiMessage(message) {
  try {
    const audio = message.serverContent?.modelTurn?.parts[0]?.inlineData;
    if (audio) {
      updateStatus('AIã‹ã‚‰ã®éŸ³å£°ã‚’å—ä¿¡ã—ã¾ã—ãŸã€‚ã‚­ãƒ¥ãƒ¼ã«è¿½åŠ ã—ã¾ã™...');
      try {
        const audioBuffer = await decodeAudioData(decode(audio.data));
        audioQueue.push(audioBuffer);
        if (!isPlaying) {
          playNextAudio();
        }
      } catch (e) {
        console.error('éŸ³å£°ã®ãƒ‡ã‚³ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸ:', e);
        updateStatus('ã‚¨ãƒ©ãƒ¼: éŸ³å£°ã®ãƒ‡ã‚³ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸã€‚');
      }
    }

    if (message.serverContent?.interrupted) {
      updateStatus('ä¼šè©±ãŒä¸­æ–­ã•ã‚Œã¾ã—ãŸã€‚');
      if (currentSourceRef.current) {
        currentSourceRef.current.stop();
        currentSourceRef.current = null;
      }
      audioQueue.length = 0;
      isPlaying = false;
    }
  } catch (e) {
    console.error('AIã®éŸ³å£°å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼:', e);
    updateStatus('ã‚¨ãƒ©ãƒ¼: AIã®éŸ³å£°å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸã€‚');
  }
}

async function playNextAudio() {
  if (audioQueue.length === 0) {
    updateStatus('å†ç”Ÿã‚­ãƒ¥ãƒ¼ãŒç©ºã«ãªã‚Šã¾ã—ãŸã€‚');
    isPlaying = false;
    return;
  }

  isPlaying = true;
  const audioBuffer = audioQueue.shift();

  try {
    await outputAudioContext.resume();
    const source = outputAudioContext.createBufferSource();
    const gainNode = outputAudioContext.createGain();

    gainNode.gain.value = 0.9;

    source.buffer = audioBuffer;
    source.connect(gainNode);
    gainNode.connect(outputAudioContext.destination);
    currentSourceRef.current = source;

    source.onended = () => {
      if (currentSourceRef.current === source) {
        currentSourceRef.current = null;
      }
      isPlaying = false;
      playNextAudio();
    };

    source.start();
    updateStatus('AIã‹ã‚‰ã®éŸ³å£°ã‚’å†ç”Ÿä¸­ã§ã™...');
  } catch (e) {
    console.error('éŸ³å£°ã®å†ç”Ÿã«å¤±æ•—ã—ã¾ã—ãŸ:', e);
    updateStatus('ã‚¨ãƒ©ãƒ¼: éŸ³å£°ã®å†ç”Ÿã«å¤±æ•—ã—ã¾ã—ãŸã€‚');
    currentSourceRef.current = null;
    isPlaying = false;
    playNextAudio();
  }
}

// --- ãƒã‚¤ã‚¯å‡¦ç† ---
async function startRecording() {
  if (isRecording) return;
  try {
    await inputAudioContext.resume();
    mediaStream = await navigator.mediaDevices.getUserMedia({ audio: true, video: false });
    sourceNode = inputAudioContext.createMediaStreamSource(mediaStream);
    
    audioWorkletNode = new AudioWorkletNode(inputAudioContext, 'pcm-processor');
    
    audioWorkletNode.port.onmessage = (event) => {
      if (!isRecording || !session) return;
      const pcmData = new Uint8Array(event.data);
      try {
        session.sendRealtimeInput({
          media: {
            data: encode(pcmData),
            mimeType: `audio/pcm;rate=${INPUT_SAMPLE_RATE}`,
          }
        });
      } catch (e) {
        if (isRecording) console.error('éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã®é€ä¿¡ã«å¤±æ•—:', e);
      }
    };

    sourceNode.connect(audioWorkletNode);
    audioWorkletNode.connect(inputAudioContext.destination);
    isRecording = true;
    updateStatus('ğŸ”´ ä¼šè©±ã‚’é–‹å§‹ã—ã¾ã—ãŸã€‚è©±ã—ã‹ã‘ã¦ã¿ã¦ãã ã•ã„ã€‚');
  } catch (e) {
    console.error('ãƒã‚¤ã‚¯ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã«å¤±æ•—:', e);
    updateStatus(`ã‚¨ãƒ©ãƒ¼: ãƒã‚¤ã‚¯ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ã«å¤±æ•—ã—ã¾ã—ãŸ - ${e.message}`);
  }
}

function stopRecording() {
  if (!isRecording) return;
  isRecording = false;
  updateStatus('ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’çµ‚äº†ã—ã¦ã„ã¾ã™...');

  if (audioWorkletNode) audioWorkletNode.disconnect();
  if (sourceNode) sourceNode.disconnect();
  if (mediaStream) mediaStream.getTracks().forEach(track => track.stop());
  if (session) session.close();

  audioWorkletNode = null;
  sourceNode = null;
  mediaStream = null;
  session = null;
  
  updateStatus('ç·´ç¿’ãŒçµ‚äº†ã—ã¾ã—ãŸã€‚ã“ã®ã‚¿ãƒ–ã¯é–‰ã˜ã¦æ§‹ã„ã¾ã›ã‚“ã€‚');
  stopButton.disabled = true;
}

// --- ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•° ---
function encode(bytes) {
  let binary = '';
  const len = bytes.byteLength;
  for (let i = 0; i < len; i++) {
    binary += String.fromCharCode(bytes[i]);
  }
  return btoa(binary);
}

function decode(base64) {
  const binaryString = atob(base64);
  const len = binaryString.length;
  const bytes = new Uint8Array(len);
  for (let i = 0; i < len; i++) {
    bytes[i] = binaryString.charCodeAt(i);
  }
  return bytes;
}

async function decodeAudioData(data) {
  const numChannels = 1; // Geminiã‹ã‚‰ã®éŸ³å£°ã¯ãƒ¢ãƒãƒ©ãƒ«ã¨ä»®å®š

  // utils.ts ã®å®Ÿè£…ã«å®Œå…¨ã«æº–æ‹ ã—ã€å…ˆã«ãƒãƒƒãƒ•ã‚¡ã‚’ä½œæˆ
  const buffer = outputAudioContext.createBuffer(
    numChannels,
    data.length / 2 / numChannels,
    outputAudioContext.sampleRate
  );

  const dataInt16 = new Int16Array(data.buffer, data.byteOffset, data.length / 2);
  const dataFloat32 = new Float32Array(dataInt16.length);
  for (let i = 0; i < dataInt16.length; i++) {
    dataFloat32[i] = dataInt16[i] / 32768.0;
  }

  // utils.ts ã®å®Ÿè£…ã«å®Œå…¨ã«æº–æ‹ ã—ã€ãƒãƒ£ãƒ³ãƒãƒ«åˆ†é›¢ãƒ«ãƒ¼ãƒ—ã‚’å®Ÿè£…
  // (ãƒ¢ãƒãƒ©ãƒ«ã®å ´åˆã¯å®Ÿè³ªçš„ã« buffer.copyToChannel(dataFloat32, 0) ã¨ç­‰ä¾¡)
  for (let i = 0; i < numChannels; i++) {
    const channel = dataFloat32.filter((_, index) => index % numChannels === i);
    buffer.copyToChannel(channel, i);
  }

  return buffer;
}

function updateStatus(message) {
  console.log(message);
  statusDiv.textContent = message;
}

// --- ã‚¤ãƒ™ãƒ³ãƒˆãƒªã‚¹ãƒŠãƒ¼ ---
stopButton.addEventListener('click', stopRecording);

// --- å®Ÿè¡Œé–‹å§‹ ---
main();
